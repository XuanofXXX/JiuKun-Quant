{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","import re\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","from matplotlib.gridspec import GridSpec\n","from matplotlib.collections import LineCollection\n","import seaborn as sns\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def pre_processing(df):\n","    df['MidPrice'] = (df['AskPrice1'] * df['AskVolume1'] + df['BidPrice1'] * df['BidVolume1']) / (df['AskVolume1'] + df['BidVolume1'])\n","    df['position_change'] = df.groupby('StockID')['share_holding'].diff()\n","    df['ticks_since_last_change'] = df.groupby('StockID').apply(lambda x: x['Tick'] - x['Tick'].where(x['position_change'] != 0).ffill()).reset_index(level=0, drop=True)\n","    return df\n","\n","def calculate_vwap(df: pd.DataFrame):\n","    df['CumulativeVolume'] = df['share_holding'].cumsum()\n","    df['CumulativeValue'] = df['trade_value'].cumsum()\n","    df['VWAP'] = abs(df['CumulativeValue'] / df['CumulativeVolume'])\n","    return df\n","\n","def plot_all_stocks_with_vwap(df, output_folder='stock_plots'):\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","\n","    df = df.groupby('StockID').apply(calculate_vwap).reset_index(drop=True)\n","\n","    for stock_id in df['StockID'].unique():\n","        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n","        fig.suptitle(f'Stock {stock_id}: Price, VWAP, and Trading Activity', fontsize=16)\n","        \n","        stock_data = df[df['StockID'] == stock_id]\n","        \n","        # Plot price\n","        ax1.plot(stock_data['Tick'], stock_data['MidPrice'], label='Mid Price', color='b', linewidth=1.5)\n","        ax1.fill_between(stock_data['Tick'], stock_data['BidPrice1'], stock_data['AskPrice1'], \n","                         alpha=0.2, color='gray', label='Bid-Ask Spread')\n","        \n","        # Plot colored VWAP\n","        has_positive = (stock_data['position_change'] > 0).any()\n","        color = 'green' if has_positive else 'red'\n","        ax1.plot(stock_data['Tick'], stock_data['VWAP'], label='My_vwap', color=color, linestyle='--', linewidth=1.5)\n","        ax1.plot(stock_data['Tick'], stock_data['twap'], label='twao', color='grey', linestyle='--', linewidth=1.5)\n","        \n","        ax1.set_ylabel('Price', fontsize=12)\n","        ax1.tick_params(axis='y', labelsize=10)\n","        \n","        # Set y-axis limits for price plot\n","        price_range = stock_data['MidPrice'].max() - stock_data['MidPrice'].min()\n","        ax1.set_ylim(stock_data['MidPrice'].min() - price_range*0.1, \n","                     stock_data['MidPrice'].max() + price_range*0.1)\n","        \n","        # Mark points where trading occurred\n","        buys = stock_data[stock_data['position_change'] > 0]\n","        sells = stock_data[stock_data['position_change'] < 0]\n","        ax1.scatter(buys['Tick'], buys['MidPrice'], color='g', s=50, label='Buy', marker='^', zorder=5)\n","        ax1.scatter(sells['Tick'], sells['MidPrice'], color='r', s=50, label='Sell', marker='v', zorder=5)\n","        \n","        ax1.legend(fontsize=10, loc='upper left')\n","        \n","        # Plot share holding and target volume\n","        ax2.plot(stock_data['Tick'], stock_data['share_holding'], color='b', alpha=0.7, label='Share Holding', linewidth=1.5)\n","        ax2.plot(stock_data['Tick'], stock_data['target_volume'], color='m', alpha=0.7, label='Target Volume', linewidth=1.5)\n","        ax2.set_ylabel('Volume', fontsize=12)\n","        ax2.tick_params(axis='y', labelsize=10)\n","        \n","        # Plot trade volume as bars\n","        trade_volume = stock_data['position_change'].abs()\n","        ax2.bar(stock_data['Tick'], trade_volume, alpha=0.3, color='g', label='Trade Volume')\n","        \n","        ax2.legend(fontsize=10, loc='upper left')\n","        \n","        ax2.set_xlabel('Tick', fontsize=12)\n","        ax2.tick_params(axis='x', labelsize=10)\n","        \n","        plt.tight_layout()\n","        \n","        filename = f'{stock_id}_plot.png'\n","        filepath = os.path.join(output_folder, filename)\n","        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","        \n","        print(f\"Saved plot for {stock_id} to {filepath}\")\n","        \n","def stitch_images(directory, output_prefix, columns=5, max_rows_per_image=5):\n","    # 获取目录下所有图片文件\n","    image_files = sorted([f for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))])\n","    \n","    # 打开第一个图片以获取尺寸\n","    with Image.open(os.path.join(directory, image_files[0])) as img:\n","        width, height = img.size\n","    \n","    # 计算每个批次的图片数量\n","    images_per_batch = columns * max_rows_per_image\n","    \n","    # 批量处理图片\n","    for batch, i in enumerate(range(0, len(image_files), images_per_batch)):\n","        batch_files = image_files[i:i+images_per_batch]\n","        \n","        # 计算当前批次的行数\n","        rows = (len(batch_files) + columns - 1) // columns\n","        \n","        # 创建新图片\n","        result = Image.new('RGB', (width * columns, height * rows))\n","        \n","        # 粘贴图片\n","        for idx, f in enumerate(batch_files):\n","            with Image.open(os.path.join(directory, f)) as img:\n","                x = (idx % columns) * width\n","                y = (idx // columns) * height\n","                result.paste(img, (x, y))\n","        \n","        # 保存结果\n","        output_file = f\"{output_prefix}_batch_{batch+1}.png\"\n","        result.save(os.path.join(directory, output_file))\n","        print(f\"Saved {output_file}\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def calculate_scores(df):\n","    df = df.groupby('StockID').apply(calculate_vwap).reset_index(drop=True)\n","    \n","    # 计算未完成量\n","    df['unfinished_volume'] = df['target_volume'] - df['share_holding']\n","    \n","    # 模拟收盘时强制平仓\n","    df['final_trade_value'] = df['unfinished_volume'] * df['MidPrice']\n","    df['final_trade_volume'] = df['unfinished_volume'].abs()\n","    \n","    # 计算最终的VWAP\n","    df['final_VWAP'] = np.where(\n","        df['CumulativeVolume'] + df['final_trade_volume'] != 0,\n","        (df['CumulativeValue'] + df['final_trade_value']) / (df['CumulativeVolume'] + df['final_trade_volume']),\n","        df['MidPrice']  # 如果分母为0，使用当前中间价格\n","    )\n","    \n","    # 计算得分\n","    df['trade_direction'] = np.sign(df['target_volume'])\n","    df['score'] = (1 - df['final_VWAP'] / df['twap']) * df['trade_direction'] + 0.0004\n","    \n","    return df\n","\n","def plot_score_histogram(df, output_folder='stock_plots'):\n","    scores = df.groupby('StockID')['score'].last()\n","    \n","    plt.figure(figsize=(12, 6))\n","    plt.hist(scores, bins=20, edgecolor='black')\n","    plt.title('Distribution of Stock Scores')\n","    plt.xlabel('Score')\n","    plt.ylabel('Frequency')\n","    \n","    # 计算当日总得分\n","    mean_score = scores.mean()\n","    score_std = scores.std()\n","    total_score = np.abs(mean_score) * (mean_score / score_std)\n","    \n","    plt.text(0.95, 0.95, \n","             f'Mean Score: {mean_score:.6f}\\n'\n","             f'Score Std: {score_std:.6f}\\n'\n","             f'Total Score: {total_score:.6f}', \n","             transform=plt.gca().transAxes, \n","             horizontalalignment='right', \n","             verticalalignment='top', \n","             fontsize=12)\n","    \n","    filename = 'score_histogram.png'\n","    filepath = os.path.join(output_folder, filename)\n","    plt.savefig(filepath, dpi=300, bbox_inches='tight')\n","    plt.close()\n","    \n","    print(f\"Saved score histogram to {filepath}\")\n","    \n","    # 保存总得分到文本文件\n","    with open(os.path.join(output_folder, 'total_score.txt'), 'w') as f:\n","        f.write(f'Mean Score: {mean_score:.6f}\\n')\n","        f.write(f'Score Std: {score_std:.6f}\\n')\n","        f.write(f'Total Score: {total_score:.6f}\\n')\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["game = '083110'\n","day = 2\n","\n","csv_path = os.path.join(\n","    './snapshots/',\n","    f'{game}-day{day}_all_stocks.csv'\n","    )\n","\n","df = pd.read_csv(csv_path)\n","\n","output_folder = f'./analysis/{game}_day{day}'"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["df = df.drop_duplicates(subset='Tick')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tick</th>\n","      <th>StockID</th>\n","      <th>AskPrice1</th>\n","      <th>AskPrice2</th>\n","      <th>AskPrice3</th>\n","      <th>AskPrice4</th>\n","      <th>AskPrice5</th>\n","      <th>AskPrice6</th>\n","      <th>AskPrice7</th>\n","      <th>AskPrice8</th>\n","      <th>...</th>\n","      <th>last_price</th>\n","      <th>twap</th>\n","      <th>share_holding</th>\n","      <th>orders</th>\n","      <th>error_orders</th>\n","      <th>order_value</th>\n","      <th>trade_value</th>\n","      <th>target_volume</th>\n","      <th>remain_volume</th>\n","      <th>frozen_volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1</td>\n","      <td>UBIQ000</td>\n","      <td>60.45</td>\n","      <td>60.46</td>\n","      <td>60.47</td>\n","      <td>60.48</td>\n","      <td>60.49</td>\n","      <td>60.50</td>\n","      <td>60.51</td>\n","      <td>60.52</td>\n","      <td>...</td>\n","      <td>60.44</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3400</td>\n","      <td>3400</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>0</td>\n","      <td>UBIQ000</td>\n","      <td>60.45</td>\n","      <td>60.46</td>\n","      <td>60.47</td>\n","      <td>60.48</td>\n","      <td>60.49</td>\n","      <td>60.50</td>\n","      <td>60.51</td>\n","      <td>60.52</td>\n","      <td>...</td>\n","      <td>60.43</td>\n","      <td>60.440000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3400</td>\n","      <td>3400</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>1</td>\n","      <td>UBIQ000</td>\n","      <td>60.45</td>\n","      <td>60.46</td>\n","      <td>60.47</td>\n","      <td>60.48</td>\n","      <td>60.49</td>\n","      <td>60.50</td>\n","      <td>60.51</td>\n","      <td>60.52</td>\n","      <td>...</td>\n","      <td>60.43</td>\n","      <td>60.435312</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3400</td>\n","      <td>3400</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>2</td>\n","      <td>UBIQ000</td>\n","      <td>60.45</td>\n","      <td>60.46</td>\n","      <td>60.47</td>\n","      <td>60.48</td>\n","      <td>60.49</td>\n","      <td>60.50</td>\n","      <td>60.51</td>\n","      <td>60.52</td>\n","      <td>...</td>\n","      <td>60.44</td>\n","      <td>60.437986</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3400</td>\n","      <td>3400</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>3</td>\n","      <td>UBIQ000</td>\n","      <td>60.45</td>\n","      <td>60.46</td>\n","      <td>60.47</td>\n","      <td>60.48</td>\n","      <td>60.49</td>\n","      <td>60.50</td>\n","      <td>60.51</td>\n","      <td>60.52</td>\n","      <td>...</td>\n","      <td>60.44</td>\n","      <td>60.437240</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3400</td>\n","      <td>3400</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>149800</th>\n","      <td>2995</td>\n","      <td>UBIQ000</td>\n","      <td>60.38</td>\n","      <td>60.39</td>\n","      <td>60.40</td>\n","      <td>60.41</td>\n","      <td>60.42</td>\n","      <td>60.43</td>\n","      <td>60.44</td>\n","      <td>60.45</td>\n","      <td>...</td>\n","      <td>60.38</td>\n","      <td>60.197148</td>\n","      <td>3400</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>240816</td>\n","      <td>204704</td>\n","      <td>3400</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>149850</th>\n","      <td>2996</td>\n","      <td>UBIQ000</td>\n","      <td>60.38</td>\n","      <td>60.39</td>\n","      <td>60.40</td>\n","      <td>60.41</td>\n","      <td>60.42</td>\n","      <td>60.43</td>\n","      <td>60.44</td>\n","      <td>60.45</td>\n","      <td>...</td>\n","      <td>60.38</td>\n","      <td>60.197216</td>\n","      <td>3400</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>240816</td>\n","      <td>204704</td>\n","      <td>3400</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>149900</th>\n","      <td>2997</td>\n","      <td>UBIQ000</td>\n","      <td>60.38</td>\n","      <td>60.39</td>\n","      <td>60.40</td>\n","      <td>60.41</td>\n","      <td>60.42</td>\n","      <td>60.43</td>\n","      <td>60.44</td>\n","      <td>60.45</td>\n","      <td>...</td>\n","      <td>60.38</td>\n","      <td>60.197281</td>\n","      <td>3400</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>240816</td>\n","      <td>204704</td>\n","      <td>3400</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>149950</th>\n","      <td>2998</td>\n","      <td>UBIQ000</td>\n","      <td>60.39</td>\n","      <td>60.40</td>\n","      <td>60.41</td>\n","      <td>60.42</td>\n","      <td>60.43</td>\n","      <td>60.44</td>\n","      <td>60.45</td>\n","      <td>60.46</td>\n","      <td>...</td>\n","      <td>60.37</td>\n","      <td>60.197348</td>\n","      <td>3400</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>240816</td>\n","      <td>204704</td>\n","      <td>3400</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>150000</th>\n","      <td>2999</td>\n","      <td>UBIQ000</td>\n","      <td>60.39</td>\n","      <td>60.40</td>\n","      <td>60.41</td>\n","      <td>60.42</td>\n","      <td>60.43</td>\n","      <td>60.44</td>\n","      <td>60.45</td>\n","      <td>60.46</td>\n","      <td>...</td>\n","      <td>60.37</td>\n","      <td>60.197348</td>\n","      <td>3400</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>240816</td>\n","      <td>204704</td>\n","      <td>3400</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2285 rows × 56 columns</p>\n","</div>"],"text/plain":["        Tick  StockID  AskPrice1  AskPrice2  AskPrice3  AskPrice4  AskPrice5  \\\n","0         -1  UBIQ000      60.45      60.46      60.47      60.48      60.49   \n","50         0  UBIQ000      60.45      60.46      60.47      60.48      60.49   \n","100        1  UBIQ000      60.45      60.46      60.47      60.48      60.49   \n","150        2  UBIQ000      60.45      60.46      60.47      60.48      60.49   \n","200        3  UBIQ000      60.45      60.46      60.47      60.48      60.49   \n","...      ...      ...        ...        ...        ...        ...        ...   \n","149800  2995  UBIQ000      60.38      60.39      60.40      60.41      60.42   \n","149850  2996  UBIQ000      60.38      60.39      60.40      60.41      60.42   \n","149900  2997  UBIQ000      60.38      60.39      60.40      60.41      60.42   \n","149950  2998  UBIQ000      60.39      60.40      60.41      60.42      60.43   \n","150000  2999  UBIQ000      60.39      60.40      60.41      60.42      60.43   \n","\n","        AskPrice6  AskPrice7  AskPrice8  ...  last_price       twap  \\\n","0           60.50      60.51      60.52  ...       60.44   0.000000   \n","50          60.50      60.51      60.52  ...       60.43  60.440000   \n","100         60.50      60.51      60.52  ...       60.43  60.435312   \n","150         60.50      60.51      60.52  ...       60.44  60.437986   \n","200         60.50      60.51      60.52  ...       60.44  60.437240   \n","...           ...        ...        ...  ...         ...        ...   \n","149800      60.43      60.44      60.45  ...       60.38  60.197148   \n","149850      60.43      60.44      60.45  ...       60.38  60.197216   \n","149900      60.43      60.44      60.45  ...       60.38  60.197281   \n","149950      60.44      60.45      60.46  ...       60.37  60.197348   \n","150000      60.44      60.45      60.46  ...       60.37  60.197348   \n","\n","        share_holding  orders  error_orders  order_value  trade_value  \\\n","0                   0       0             0            0            0   \n","50                  0       0             0            0            0   \n","100                 0       0             0            0            0   \n","150                 0       0             0            0            0   \n","200                 0       0             0            0            0   \n","...               ...     ...           ...          ...          ...   \n","149800           3400      25             0       240816       204704   \n","149850           3400      25             0       240816       204704   \n","149900           3400      25             0       240816       204704   \n","149950           3400      25             0       240816       204704   \n","150000           3400      25             0       240816       204704   \n","\n","        target_volume  remain_volume  frozen_volume  \n","0                3400           3400              0  \n","50               3400           3400              0  \n","100              3400           3400              0  \n","150              3400           3400              0  \n","200              3400           3400              0  \n","...               ...            ...            ...  \n","149800           3400              0              0  \n","149850           3400              0              0  \n","149900           3400              0              0  \n","149950           3400              0              0  \n","150000           3400              0              0  \n","\n","[2285 rows x 56 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/7v/0pft7_9d053gl9jmqh7tn0sr0000gn/T/ipykernel_12712/3065013689.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  df['ticks_since_last_change'] = df.groupby('StockID').apply(lambda x: x['Tick'] - x['Tick'].where(x['position_change'] != 0).ffill()).reset_index(level=0, drop=True)\n","/var/folders/7v/0pft7_9d053gl9jmqh7tn0sr0000gn/T/ipykernel_12712/3065013689.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  df = df.groupby('StockID').apply(calculate_vwap).reset_index(drop=True)\n"]},{"name":"stdout","output_type":"stream","text":["Saved plot for UBIQ000 to ./analysis/083110_day1/UBIQ000_plot.png\n","Saved plot for UBIQ001 to ./analysis/083110_day1/UBIQ001_plot.png\n","Saved plot for UBIQ002 to ./analysis/083110_day1/UBIQ002_plot.png\n","Saved plot for UBIQ003 to ./analysis/083110_day1/UBIQ003_plot.png\n","Saved plot for UBIQ004 to ./analysis/083110_day1/UBIQ004_plot.png\n","Saved plot for UBIQ005 to ./analysis/083110_day1/UBIQ005_plot.png\n","Saved plot for UBIQ006 to ./analysis/083110_day1/UBIQ006_plot.png\n","Saved plot for UBIQ007 to ./analysis/083110_day1/UBIQ007_plot.png\n","Saved plot for UBIQ008 to ./analysis/083110_day1/UBIQ008_plot.png\n","Saved plot for UBIQ009 to ./analysis/083110_day1/UBIQ009_plot.png\n","Saved plot for UBIQ010 to ./analysis/083110_day1/UBIQ010_plot.png\n","Saved plot for UBIQ011 to ./analysis/083110_day1/UBIQ011_plot.png\n","Saved plot for UBIQ012 to ./analysis/083110_day1/UBIQ012_plot.png\n","Saved plot for UBIQ013 to ./analysis/083110_day1/UBIQ013_plot.png\n","Saved plot for UBIQ014 to ./analysis/083110_day1/UBIQ014_plot.png\n","Saved plot for UBIQ015 to ./analysis/083110_day1/UBIQ015_plot.png\n","Saved plot for UBIQ016 to ./analysis/083110_day1/UBIQ016_plot.png\n","Saved plot for UBIQ017 to ./analysis/083110_day1/UBIQ017_plot.png\n","Saved plot for UBIQ018 to ./analysis/083110_day1/UBIQ018_plot.png\n","Saved plot for UBIQ019 to ./analysis/083110_day1/UBIQ019_plot.png\n","Saved plot for UBIQ020 to ./analysis/083110_day1/UBIQ020_plot.png\n","Saved plot for UBIQ021 to ./analysis/083110_day1/UBIQ021_plot.png\n","Saved plot for UBIQ022 to ./analysis/083110_day1/UBIQ022_plot.png\n","Saved plot for UBIQ023 to ./analysis/083110_day1/UBIQ023_plot.png\n","Saved plot for UBIQ024 to ./analysis/083110_day1/UBIQ024_plot.png\n","Saved plot for UBIQ025 to ./analysis/083110_day1/UBIQ025_plot.png\n","Saved plot for UBIQ026 to ./analysis/083110_day1/UBIQ026_plot.png\n","Saved plot for UBIQ027 to ./analysis/083110_day1/UBIQ027_plot.png\n","Saved plot for UBIQ028 to ./analysis/083110_day1/UBIQ028_plot.png\n","Saved plot for UBIQ029 to ./analysis/083110_day1/UBIQ029_plot.png\n","Saved plot for UBIQ030 to ./analysis/083110_day1/UBIQ030_plot.png\n","Saved plot for UBIQ031 to ./analysis/083110_day1/UBIQ031_plot.png\n","Saved plot for UBIQ032 to ./analysis/083110_day1/UBIQ032_plot.png\n","Saved plot for UBIQ033 to ./analysis/083110_day1/UBIQ033_plot.png\n","Saved plot for UBIQ034 to ./analysis/083110_day1/UBIQ034_plot.png\n","Saved plot for UBIQ035 to ./analysis/083110_day1/UBIQ035_plot.png\n","Saved plot for UBIQ036 to ./analysis/083110_day1/UBIQ036_plot.png\n","Saved plot for UBIQ037 to ./analysis/083110_day1/UBIQ037_plot.png\n","Saved plot for UBIQ038 to ./analysis/083110_day1/UBIQ038_plot.png\n","Saved plot for UBIQ039 to ./analysis/083110_day1/UBIQ039_plot.png\n","Saved plot for UBIQ040 to ./analysis/083110_day1/UBIQ040_plot.png\n","Saved plot for UBIQ041 to ./analysis/083110_day1/UBIQ041_plot.png\n","Saved plot for UBIQ042 to ./analysis/083110_day1/UBIQ042_plot.png\n","Saved plot for UBIQ043 to ./analysis/083110_day1/UBIQ043_plot.png\n","Saved plot for UBIQ044 to ./analysis/083110_day1/UBIQ044_plot.png\n","Saved plot for UBIQ045 to ./analysis/083110_day1/UBIQ045_plot.png\n","Saved plot for UBIQ046 to ./analysis/083110_day1/UBIQ046_plot.png\n","Saved plot for UBIQ047 to ./analysis/083110_day1/UBIQ047_plot.png\n","Saved plot for UBIQ048 to ./analysis/083110_day1/UBIQ048_plot.png\n","Saved plot for UBIQ049 to ./analysis/083110_day1/UBIQ049_plot.png\n","Saved output1_batch_1.png\n","Saved output1_batch_2.png\n"]}],"source":["df = pre_processing(df)\n","plot_all_stocks_with_vwap(df, output_folder=output_folder)\n","stitch_images(output_folder, output_prefix=f'output{day}', columns=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/7v/0pft7_9d053gl9jmqh7tn0sr0000gn/T/ipykernel_17365/1445606423.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  df = df.groupby('StockID').apply(calculate_vwap).reset_index(drop=True)\n"]},{"name":"stdout","output_type":"stream","text":["Saved score histogram to ./analysis/083012_day63/score_histogram.png\n"]}],"source":["df_with_scores = calculate_scores(df)\n","\n","plot_score_histogram(df_with_scores, output_folder=output_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"undefined.undefined.undefined"}},"nbformat":4,"nbformat_minor":2}
